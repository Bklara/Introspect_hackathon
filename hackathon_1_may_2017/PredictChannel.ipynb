{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import os\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slack_export import SlackExport, normalize_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = '/Users/alex/Documents/ODS/oct_4_2016_dump'\n",
    "data_folder = './ODS_dump_Mar_10_2017'\n",
    "ods = SlackExport(data_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_msg = pd.DataFrame.from_records(ods.messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "type     subtype          \n",
       "message  0                    110721\n",
       "         bot_add                  10\n",
       "         bot_message             745\n",
       "         bot_remove                6\n",
       "         channel_archive          19\n",
       "         channel_join          24227\n",
       "         channel_leave           761\n",
       "         channel_name             28\n",
       "         channel_purpose          61\n",
       "         channel_topic            56\n",
       "         channel_unarchive         1\n",
       "         file_comment             24\n",
       "         file_mention             11\n",
       "         file_share             1202\n",
       "         me_message                2\n",
       "         pinned_item              88\n",
       "Name: dt, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_msg.fillna(0).groupby(['type', 'subtype'])['dt'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_texts = [\n",
    "    normalize_links(msg['text'])\n",
    "    for msg in ods.messages\n",
    "    if msg['type'] == 'message' and msg.get('subtype') is None\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "anybody = '?'.decode('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22396"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = filter(lambda x: anybody in x.lower() ,all_texts)\n",
    "\n",
    "len(filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "почему? Другими словами вы разрешаете делать разные монотонные преобразования над фичами и утверждаете, что порядок сплитов и по каким переменным каждый сплит сохранится?   Хотелось бы почитать доказательство. Если на шаге i выбрана таже фича для сплита, что в исходном дереве, то вопросов нет. Но почему будет выбрана имена она?\n",
      "------------------------------\n",
      "@U041SH27M   ну так не понял, где искать вас. в субботу тогда? ;)\n",
      "------------------------------\n",
      "текст слева, текст справа -- это текст одной категории и текст другой категории?\n",
      "------------------------------\n",
      "Как так?\n",
      "------------------------------\n",
      "@U041SH27M: а чем не аналитика? Вполне себе. Deep learning в том же маркетинге никому не упал.\n",
      "------------------------------\n",
      "Можете проверить звук сейчас норм?\n",
      "------------------------------\n",
      "А что такое \"колметоды\"?\n",
      "------------------------------\n",
      "тут да, отличие всего в 2 символа. А если так:\n",
      "\"СуШ1(а БХК ЧЕЛНОЧОК 400(. ,, ПЛ/ПАК\" и \"сушка бхк челночок 400г пл/пак\"?\n",
      "------------------------------\n",
      "!here:  ребят, а что значит разместить решение в публичном доступе для текущего конкурса Каггл? \n",
      "если на гитхабе лежит - это считается?\n",
      "или нужно на форуме каггла разместить?\n",
      "------------------------------\n",
      "А это не те ребята, которые набирали в прошлом (?) году 100 аналитиков, чтобы в конце остался только один?\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _msg in sample(filtered, 10):\n",
    "    print(_msg)\n",
    "    print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem.snowball import EnglishStemmer, RussianStemmer\n",
    "\n",
    "ru_stemmer = RussianStemmer()\n",
    "en_stemmer = EnglishStemmer()\n",
    "analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def is_russian_word(w):\n",
    "    if not isinstance(w, unicode):\n",
    "        w = w.decode('utf8')\n",
    "    for c in w:\n",
    "        if ord(c) >= ord(u'а') and ord(c) <= ord(u'я'):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    for w in analyzer(doc):\n",
    "        yield ru_stemmer.stem(w) if is_russian_word(w) else en_stemmer.stem(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 9s, sys: 1.79 s, total: 2min 11s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "vectorizer = TfidfVectorizer(min_df=5, analyzer=stemmed_words).fit(all_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "north\tбрр\tразработок\tпрерыван\t100014\tмалахов\t0e90e3f79329\tотправлен\tpedobear\tc1h4gglmr\tresearch_discussion_stacked_approxim\tbadass\tblas_mkl_info\trichrelev\tзаболеют\tвостряк\tмалоизвестн\tколокейт\t13085\tнедосуг\telections2011\tizbirkom2\t0o8\tприсоветова\tспим\tytn\tколдовств\t216\tjlevi\tметеоризм\tflavor\tвентилирован\tгадан\tвяж\tbmstu\tdietrich\tmain_en\trtree\tburger\t597s110111n\tвашингтонск\tcodalabtemp\tстекловат\tнавчан\tсенсац\tмалац\tнакрыт\tkuroyanagi\tнестра\tматематичненьк\tфункшенс\tподбега\tнажра\tугорет\tжиробас\tзашит\tгитлаб\tсосдеств\tx_max_depth\tltr\tp1469619524000109\tсаутсорс\tpllb7e2g7aspssa_plfewnd6\tff77cc0a8d29\tорегон\tfandom\tаптек\tподсос\tprodukte_rootserv\tлицензион\tпонын\ttjurjuwbb\tотягча\tдруид\tтретьекурсниц\tскопипастнул\tcjlin\tбейт\tcomplete_separation_logit_model\tперелива\tj0zpiiso\t231699\tbeefsteak\tзабив\tnuma\tнетехническ\t200gib\tхахах\tdailydot\t35181\tтрэч\t1842\tтелескопическ\t_________________________________\tканистр\temeraldgrouppublish\tветхост\tpermut\tнастольник\ttg1mumpwvrml6qd0\t"
     ]
    }
   ],
   "source": [
    "for _item in sample(vectorizer.stop_words_,100):\n",
    "    print(_item,end='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ящик 14900\n",
      "ячейк 14899\n",
      "ячеек 14898\n",
      "яхт 14897\n",
      "ясност 14896\n",
      "ясн 14895\n",
      "ярмарк 14894\n",
      "ярлык 14893\n",
      "яркост 14892\n",
      "ярк 14891\n",
      "ярд 14890\n",
      "японск 14889\n",
      "япон 14888\n",
      "яп 14887\n",
      "яндексоид 14886\n",
      "яндексовск 14885\n",
      "яндексов 14884\n",
      "яндекс 14883\n",
      "январ 14882\n",
      "ян 14881\n"
     ]
    }
   ],
   "source": [
    "for _word, _count in sorted(vectorizer.vocabulary_.items(),key=itemgetter(1),reverse=True)[:20]:\n",
    "    print(_word,end=' ')\n",
    "    print(_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'channel': u'C1CFSK1NW',\n",
       " 'dt': datetime.datetime(2016, 6, 6, 18, 15, 37, 3),\n",
       " u'members': [u'U04CH4QBD', u'U09BY2N3X', u'U0JNAUT99'],\n",
       " u'subtype': u'channel_archive',\n",
       " u'text': u'<@U04CH4QBD|ermakovpetr> archived the channel (w/ 3 members)',\n",
       " u'ts': 1465226137.000003,\n",
       " u'type': u'message',\n",
       " u'user': u'U04CH4QBD'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_texts = [\n",
    "    normalize_links(msg['text'])\n",
    "    for msg in ods.messages\n",
    "    if msg['type'] == 'message' and msg.get('subtype') is None\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reaction classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "react_texts = []\n",
    "react_counts = []\n",
    "\n",
    "for msg in ods.messages:\n",
    "    if msg['type'] == 'message' and msg.get('subtype') is None:\n",
    "        react_texts.append(normalize_links(msg['text']))\n",
    "        \n",
    "        msg_reacts = {}\n",
    "        for record in msg.get('reactions', []):\n",
    "            msg_reacts[record['name']] = record['count']\n",
    "        react_counts.append(msg_reacts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "unique_reacts = collections.Counter()\n",
    "for c in react_counts:\n",
    "    for r in c:\n",
    "        unique_reacts[r] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_reacts = [r for r, c in unique_reacts.most_common(20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = vectorizer.transform(react_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import StratifiedShuffleSplit, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+1, positives 3.15%, cv auc 0.74158\n",
      "heavy_plus_sign, positives 1.57%, cv auc 0.66345\n",
      "joy, positives 0.50%, cv auc 0.70246\n",
      "trollface, positives 0.34%, cv auc 0.65444\n",
      "thinking_face, positives 0.34%, cv auc 0.66133\n",
      "metal, positives 0.28%, cv auc 0.77424\n",
      "100, positives 0.24%, cv auc 0.63487\n",
      "parrot, positives 0.21%, cv auc 0.73555\n",
      "muscle, positives 0.21%, cv auc 0.75717\n",
      "but_why, positives 0.20%, cv auc 0.67768\n",
      "eyes, positives 0.20%, cv auc 0.55336\n",
      "aussieparrot, positives 0.20%, cv auc 0.71491\n",
      "putin, positives 0.19%, cv auc 0.69807\n",
      "white_check_mark, positives 0.17%, cv auc 0.59538\n",
      "slava, positives 0.16%, cv auc 0.74864\n",
      "facepalm, positives 0.13%, cv auc 0.62229\n",
      "feelsgood, positives 0.13%, cv auc 0.56028\n",
      "levenchuk, positives 0.13%, cv auc 0.71326\n",
      "ban, positives 0.11%, cv auc 0.70853\n",
      "youknow, positives 0.11%, cv auc 0.57877\n"
     ]
    }
   ],
   "source": [
    "model_react = {}\n",
    "for react_target in selected_reacts:\n",
    "    y = np.array([int(c.get(react_target, 0) > 0) for c in react_counts])\n",
    "    model_react[react_target] = LogisticRegression().fit(X, y)\n",
    "\n",
    "    cv = StratifiedShuffleSplit(y, random_state=123, test_size=.15, train_size=.85, n_iter=3)\n",
    "    print '%s, positives %.2f%%, cv auc %.5f' % (\n",
    "        react_target,\n",
    "        y.mean()*100,\n",
    "        cross_val_score(LogisticRegression(), X, y, cv=cv, scoring='roc_auc').mean(),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def top_reactions(text):\n",
    "    x = vectorizer.transform([text])\n",
    "    preds = [\n",
    "        (r, model_react[r].predict_proba(x)[0, 1])\n",
    "        for r in selected_reacts\n",
    "    ]\n",
    "    preds.sort(key=lambda (r, p): p, reverse=True)\n",
    "    return preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'+1', 0.031918339825498104),\n",
       " (u'heavy_plus_sign', 0.014286038840257299),\n",
       " (u'thinking_face', 0.0046909572491761276),\n",
       " (u'trollface', 0.0041309662885016096),\n",
       " (u'slava', 0.0039838725771864291)]"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reactions(u'Можно. Тут пара человек угорала с истории про козла')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'+1', 0.019815695123274447),\n",
       " (u'heavy_plus_sign', 0.011856093208197686),\n",
       " (u'putin', 0.010068268864851336),\n",
       " (u'trollface', 0.0093261077915930933),\n",
       " (u'joy', 0.0065046704319646226)]"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reactions(u'И мемесы у нас русские')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'heavy_plus_sign', 0.018157298143154872),\n",
       " (u'+1', 0.013539816190672476),\n",
       " (u'trollface', 0.0082548602457012139),\n",
       " (u'joy', 0.0065746048791814034),\n",
       " (u'putin', 0.0051477862065029394)]"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reactions(u'русских у нас и так хватает')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'+1', 0.038385176875187284),\n",
       " (u'heavy_plus_sign', 0.01267402335827319),\n",
       " (u'thinking_face', 0.0039334486914132088),\n",
       " (u'metal', 0.0035588699999281213),\n",
       " (u'100', 0.0030812867555780484)]"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reactions(u'Есть ли здесь люди, которые работают DS в аптечных сетях? Можете ли вы привести примеры конкретных задач, решенных вами и которые имели конкретный результат, выразившийся в увеличении продаж или снижении затрат?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'heavy_plus_sign', 0.05352472707854166),\n",
       " (u'+1', 0.029715544162347621),\n",
       " (u'thinking_face', 0.0073329487286867365),\n",
       " (u'joy', 0.0049451150425887276),\n",
       " (u'trollface', 0.0031770037231480318)]"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_reactions(u'Т.е. на самом деле это не они ему придумали, а он такой \"ребят своим говором вы называете меня зефиркой, давайте-ка лучше придумаем немецкое имя\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Channel classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'collections' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-0466471eae01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchannel_messages_cnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcollections\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchannel_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mselected_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchannel_messages_cnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mchannel_messages_cnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'collections' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "channel_messages_cnt = collections.Counter(channel_labels)\n",
    "selected_channels = [r for r, c in channel_messages_cnt.most_common(50)]\n",
    "channel_messages_cnt.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_texts = []\n",
    "channel_labels = []\n",
    "\n",
    "for msg in ods.messages:\n",
    "    if msg['type'] == 'message' and msg.get('subtype') is None and ods.channels[msg['channel']]['name'] in selected_channels:\n",
    "        channel_texts.append(normalize_links(msg['text']))\n",
    "        channel_labels.append(ods.channels[msg['channel']]['name'])\n",
    "        \n",
    "X_channel = vectorizer.transform(channel_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.181920245541\n",
      "0.187385121118\n",
      "0.189705231823\n"
     ]
    }
   ],
   "source": [
    "for train_indices, test_indices in cv:\n",
    "    model = LogisticRegression().fit(X_channel[train_indices, :], np.array(channel_labels)[train_indices])\n",
    "    y_true = np.vstack([\n",
    "        [int(ch == l) for ch in model.classes_]\n",
    "        for l in channel_labels\n",
    "    ])\n",
    "    sc = average_precision_score(y_true[test_indices, :], model.predict_proba(X_channel[test_indices, :]))\n",
    "    print sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_channel = LogisticRegression().fit(X_channel, np.array(channel_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_channel(text):\n",
    "    X = vectorizer.transform([text])\n",
    "    y_pred = model_channel.predict_proba(X)\n",
    "    preds = zip(model_channel.classes_, y_pred[0, :])\n",
    "    preds.sort(key=lambda (c, p): p, reverse=True)\n",
    "    return preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'theory_and_practice', 0.16790929041550848),\n",
       " (u'python', 0.15014067919781149),\n",
       " (u'_random_flood', 0.087561429305589536),\n",
       " (u'_general', 0.071414662006578311),\n",
       " (u'big_data', 0.071126243710510059)]"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'подскажите пожалуйста как запустить факторизационные машины')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'_meetings', 0.44959758801100247),\n",
       " (u'theory_and_practice', 0.19180315910086793),\n",
       " (u'_random_flood', 0.046230132693773567),\n",
       " (u'conference', 0.026185563394516838),\n",
       " (u'_general', 0.024911607092178777)]"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'Слайды с семинара в ИППИ на прошлой неделе на тему \"Математические модели временных рядов с трендом в задачах обнаружения разладки\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'_random_flood', 0.20119753387775735),\n",
       " (u'_meetings', 0.084453090868886332),\n",
       " (u'_general', 0.083119532724364092),\n",
       " (u'python', 0.067297056103339165),\n",
       " (u'mltrainings_beginners', 0.064526763286998134)]"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'интересно, почему возраст - обязательное поле при регистрации')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'_jobs', 0.31460292258060213),\n",
       " (u'career', 0.17843483191938694),\n",
       " (u'welcome', 0.10548385943118249),\n",
       " (u'_random_flood', 0.095441132554945046),\n",
       " (u'_general', 0.043160697662964993)]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'''\n",
    "Всем привет\n",
    "\n",
    "В компании Criteo есть интересные позиции Data Scientist и Machine Learning Engineer разных уровней. В основном в Европе (Париж, Барселона, Амстердам, Лондон и др.), но есть также в США и Азии.\n",
    "\n",
    "Например, есть позиция Sr. Data Analyst, где надо анализировать покупательную заинтересованность людей в оффлайн магазинах и матчить ее с данными в онлайн. Оффлайн данные поступают с маячков (iBeacons).\n",
    "\n",
    "Есть несколько других позиций связанные с улучшением алгоритмов движка Criteo, рекомендательной системой и обработки больших данных.\n",
    "\n",
    "Позиции full-time, on-site. Компания помогает с переездом (visa + relocation bonus).\n",
    "\n",
    "Вот видео как круто в Criteo: https://youtu.be/i1zC3H3_gik\n",
    "\n",
    "Если кого-то заинтересует, дайте знать, я помогу.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'theory_and_practice', 0.18742089350918822),\n",
       " (u'_random_flood', 0.17149058537958456),\n",
       " (u'deep_learning', 0.10809625622781312),\n",
       " (u'_meetings', 0.08422849061490377),\n",
       " (u'_jobs', 0.064569827995280271)]"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'а можно про оффхип по подробнее?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'big_data', 0.4067488429811868),\n",
       " (u'_random_flood', 0.13176042483251368),\n",
       " (u'_meetings', 0.069866712736964848),\n",
       " (u'theory_and_practice', 0.038138175807033971),\n",
       " (u'_general', 0.036084586040766996)]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'вы hue не используете?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'_random_flood', 0.17477553287773115),\n",
       " (u'theory_and_practice', 0.11370610353653217),\n",
       " (u'_general', 0.096752516918349366),\n",
       " (u'python', 0.075395133041503692),\n",
       " (u'deep_learning', 0.074907382919993187)]"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'А есть докер образы со всем что нужно на кэггле? ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'theory_and_practice', 0.44678177339450326),\n",
       " (u'kaggle_crackers', 0.1769167991205596),\n",
       " (u'deep_learning', 0.049848548157015518),\n",
       " (u'_general', 0.033862639874370964),\n",
       " (u'python', 0.033203761366450653)]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'а кто подскажет ответ на такой примитивный вопрос (смотрю в датасет bosch) - если я обнаруживаю две фичи с четкой линейной корреляцией - какая общая рекомендация что с ними делать? Выкинуть одну? Попытаться как-то извлечь информацию из второй? Что-то еще?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'edu_courses', 0.31219710104772791),\n",
       " (u'_random_flood', 0.071867109523670036),\n",
       " (u'python', 0.062321987276667608),\n",
       " (u'deep_learning', 0.058391603568720113),\n",
       " (u'visualization', 0.051522759150720111)]"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_channel(u'ты его проходишь? ну и как последняя домашка? А по Visual Recognition чего-нибудь есть? Порекомендуйте')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}