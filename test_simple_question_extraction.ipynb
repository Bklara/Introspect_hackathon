{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from slack_data_loader import SlackLoader\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from operator import itemgetter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path_to_dump = '/Users/alex/Documents/ODS/opendatascience Slack export May 20 2017/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 639/639 [00:00<00:00, 1352.56it/s]\n"
     ]
    }
   ],
   "source": [
    "exporter = SlackLoader(path_to_dump, only_channels=('deep_learning',),\n",
    "                           start_date=datetime.datetime(2017, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 7540 messages\n"
     ]
    }
   ],
   "source": [
    "print(\"Loaded {} messages\".format(len(exporter.messages)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "channel_attrs = ['id', 'name', 'created', 'creator', 'is_archived', 'is_general', 'pins', 'topic']\n",
    "\n",
    "def channels_to_df(channels):\n",
    "    full_list = []\n",
    "    for ch_id, ch_dict in channels.items():\n",
    "        new_channel_dict = {}\n",
    "        for k in channel_attrs:\n",
    "            new_channel_dict[k] = ch_dict.get(k, None)\n",
    "        new_channel_dict['num_members'] = len(ch_dict['members'])\n",
    "        new_channel_dict['purpose'] = ch_dict['purpose']['value']\n",
    "        full_list.append(new_channel_dict)\n",
    "    return pd.DataFrame(full_list).set_index('id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = channels_to_df(exporter.channels)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "qwords = (\"как\", \"какой\", \"каким\", \"зачем\", \"почему\", \"какие\", \"когда\", \"кому\", \"кто\")\n",
    "splitter = re.compile(r\"(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s\")\n",
    "\n",
    "def is_question(d):\n",
    "    x = d.lower()\n",
    "    num_words = len(x.split(' '))\n",
    "    return (num_words > 4) and ((\"?\" in x) and any(x.startswith(w) for w in qwords))\n",
    "\n",
    "def contains_sentance_with_questions(d):\n",
    "    x = d['text'].lower()\n",
    "    sents = splitter.split(x)\n",
    "    return any(map(is_question, sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = list(filter(contains_sentance_with_questions, exporter.messages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 130 questions\n"
     ]
    }
   ],
   "source": [
    "print(\"found {} questions\".format(len(questions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2. В вероятностном подходе по машинному обучению задача обучения (MAP) ставится как W = argmax(p(D|W) * p(W)), где p(W) - априорное распределение весов, D - обучающая выборка, p(D|W) = p(x_1|W)p(x_2|W)...p(x_N|W), p(x|W) - вероятность появления x, т.е. p(x|W) - не произвольная функция, а положительная и суммируется к единице, Если f(x, W) - нейросеть, то p(x|W)=f(x,W)/integral(f(x, W))dx. Но по факту при обучении никакого интеграла не вычисляется. Как это происходит и где подробнее об этом почитать?\n",
      "----------------------------------------\n",
      "Кто-нибудь может со мной поделиться ссылками на хорошие блоги/статьи/книжки на тему image segmentation?\n",
      "----------------------------------------\n",
      "Как правильно использовать BatchNormalization в keras, в том смысле, что какие параметры втыкать в mode и axis?\n",
      "\n",
      "batch normalization втыкается после convolution2d\n",
      "\n",
      "Я правильно понимаю, что если на вход сети идет (num_batch, num_channels, X, Y)\n",
      "\n",
      "то надо\n",
      "\n",
      "`BatchNormalization(mode=0, axis=1)`\n",
      "\n",
      "?\n",
      "----------------------------------------\n",
      "Кстати, понятно, почему BN - это хорошо. Кто может поделиться опытом / литературой на тему, когда  BN - это плохо и когда его втыкать не надо?\n",
      "----------------------------------------\n",
      "кто-нибудь понимает интуицию за хитрой нелинейностью, которая используется в вейвнете?\n",
      "----------------------------------------\n",
      "Почему вокруг тф больше хайпа, чем вокруг теано?\n",
      "----------------------------------------\n",
      "почему не для продакшена тогда?\n",
      "----------------------------------------\n",
      "почему должна быть disentangled ?\n",
      "----------------------------------------\n",
      "Какого примерно размера выборку нужно иметь чтобы натренировать модель генерировать подобные?\n",
      "----------------------------------------\n",
      "У меня вопрос.\n",
      "\n",
      "Допустим, я хочу в качестве фана выложить демку модели на heroku.\n",
      "Никаких требования по perfomance нет, как и по красивости кода / интерфейса.\n",
      "Как бы вы подошли к этому вопросу?\n",
      "\n",
      "В моем воображении это такая html страница где есть поле аплоад с пост запросом. Это все внутри передается в питоновскую функцию, которая внутри вызывает модель и генерит результат. Потом это все выплевывается с каким-то форматированием обратно.\n",
      "\n",
      "Где тут можно срезать углы? Где, наоборот, высокий шанс закопаться в ненужную реализацию? Есть ли что-то специфичное для моделек DL / изображений на входе?\n",
      "----------------------------------------\n",
      "А подскажите мне, пожалуйста, батчнорм, когда его есть смысл добавлять, а когда нет? После (между) каких слоев? Какая в этом есть логика?\n",
      "----------------------------------------\n",
      "Кто-нибудь подскажет, как у Keras'овского pretrained resnet50 выходной слой поменять?\n",
      "\n",
      "Я делаю вот так:\n",
      "```\n",
      "model = ResNet50(weights='imagenet')\n",
      "model.layers.pop()\n",
      "model.outputs = [model.layers[-1].output]\n",
      "model.layers[-1].outbound_nodes = []\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "    \n",
      "```\n",
      "Вылетает со словами:\n",
      "\n",
      "```\n",
      "model.add(Dense(1, activation='sigmoid'))\n",
      "AttributeError: 'Model' object has no attribute 'add'\n",
      "\n",
      "```\n",
      "----------------------------------------\n",
      " Задача распознавания лиц из заданной базы (работники предприятия). Как обезопаситься от того, что левые люди, которых нет в базе, эмбедятся рядом с настоящими работниками и распознаются как работники предприятия? <@U041P485A> ?\n",
      "----------------------------------------\n",
      "Подскажите плс, зачем в U-net копируют свертки с этапа \"сжатия\" в соответствующий этап апсемплинга? Такое вроде во всех архитектурах для сегментации делают. Почему нельзя просто делать последовательный апсемплинг и деконволюцию без копирования более ранних этапов?\n",
      "----------------------------------------\n",
      "Подскажите, используют ли метод сопряженных градиентов для оптимизации. Почему все уперлись в SGD? \n",
      "Вот тут <http://ai.stanford.edu/~ang/papers/icml11-OptimizationForDeepLearning.pdf> коллеги утверждают, что сопряженные градиенты вполне себе\n",
      "----------------------------------------\n",
      "как насчёт real-time мониторинга на основе картинки с трансляции? :smile:\n",
      "----------------------------------------\n",
      "кто-нибудь занимался сам распознаванием действий? грубо говоря, задача примерно такая: камера смотрит на деревенских петровичей, надо определить, заняты ли они работой с птицей, пинают болт или стоят на голове\n",
      "----------------------------------------\n",
      "А может кто-нибудь по лазанье одну штуку подсказать? <https://github.com/FabianIsensee/NeuralNetworks/blob/master/NeuralNetworks/UNet.py> Здесь функция build_unet() возвращает OrderedDict. Как из него получить параметры для передачи в целевую функцию? Тупо из последнего слоя get_all_params?\n",
      "----------------------------------------\n",
      "какие архитектуры принято использовать, если нужно на входе из (n_cols, n_rows, n_channels) получить (n_cols, n_rows, 1)? \n",
      "это не каггловское распознавание дорог, если что :slightly_smiling_face:\n",
      "----------------------------------------\n",
      "хм, пробовал, но дало плохой результат. А выход какого слоя использовал? Как-то сжимал или преобразовывал выход слоя?\n",
      "----------------------------------------\n",
      "Пробую гонять fully connected сетку на данных. Какие есть эвристики для выбора размера dense слоев и их количества ?\n",
      "----------------------------------------\n",
      "рмспроп вроде с адаптивными весами по каждой координате, нет? как раз избавляясь от этой статистики вносишь дополнительную регуляризацию? вроде ты всякими рмспропами можешь загнать лр перед каким-нибудь весом в нулище и он у тебя особо обновляться не будет\n",
      "----------------------------------------\n",
      "Кто-нибудь сталкивался в своей практике с расходящимся градиентом (топовый фреймворк, стандартные слои, популярный датасет, адекватные на первый взгляд параметры) (пример обсуждения проблемы <http://stackoverflow.com/questions/38157657/salvaging-diverged-neural-networks>)? Какие могут быть причины, исключая кривые руки, и что делать в этом случае (пример инструмента для решения проблемы <http://ufldl.stanford.edu/wiki/index.php/Gradient_checking_and_advanced_optimization>)?\n",
      "----------------------------------------\n",
      "как думаете что еще за 5 кусков?\n",
      "----------------------------------------\n",
      "Кто мне подскажет, где найти код callback  в  keras, который экспеоненциальное усреднение весов делает между эпохами? (Polyak Averaging)\n",
      "----------------------------------------\n",
      "Кто нибудь сталкивался, в чем тут дело? tf 0.12, cpu\n",
      "----------------------------------------\n",
      "как перевести gated units, gated functions и прочие упоминания слова gate, когда речь об LSTM? Ворота? Гугло-переводчик говорит про какое-то стробирование.\n",
      "----------------------------------------\n",
      "Привет. Кто нибудь занимался таким упражнением: взять модель кераса (.h5), тренированную с бекендом theano, и сделать аналогичную (те же веса, структура, все) в keras но с backend'ом tensorflow? Сеть сверточная. \n",
      "Кажется, что небольшая засада должна быть с порядком осей в сверточных слоях, а все остальное должно быть такое же, но сам еще не успел это проделать.\n",
      "----------------------------------------\n",
      "Довольно часто при регистрации на летние школы (в частности по байесовским методам, о которой рассказал <@U04ELQZAU>), мероприятия по мл и при собеседовании на работу требуется провести анализ статьи на 1000-2000 слов для демонстрации понимания. Кто-нибудь может скинуть пример такого анализа любой статьи по нейронкам? Хотелось бы на конкретном примере понять, что важно, что второстепенно, на что нужно обращать внимание. Потому что я преимущественно статьи по экономике читала и анализировала раньше, а у них немного другая специфика.\n",
      "----------------------------------------\n",
      "Кто еще сомневается на счет участия в кэггле со спутниками, самое время начать!\n",
      "Я запилил кернел с полным пайплайном от картонк до csv файла:\n",
      "<https://www.kaggle.com/drn01z3/dstl-satellite-imagery-feature-detection/end-to-end-baseline-with-u-net-keras/discussion>\n",
      "И уже набралась целая банда кэгглеров 2 из которых в топ10 и участвуют в обсуждении в <#C043ZEF6K|kaggle_crackers> \n",
      "Один из них даже посвящает в свою личную жизнь (отгадайте с одного раза - кто он?)\n",
      "----------------------------------------\n",
      "Да, увеличение разрешения\n",
      "Я почему апскейлинг должен работать только если похоже на трейн сет? Почему та же логика не работает для классификации, к примеру?\n",
      "\n",
      "Я понимаю логику, что информацию нельзя “вернуть”, но ведь в реальной жизни у нас картинки очень даже предсказуемы в локальности. То есть конечно можно \"сбрить\" какие-то детали, но в среднем нет причин этому происходить\n",
      "----------------------------------------\n",
      "Кто-нибудь пробовал использовать нестандартную функцию ошибки в задаче классификации для оптимизации F1-score? Уже не первый раз сталкиваюсь с ситуацией, когда ошибка (кросс-энтропия) на валидационной выборке растёт, а с ней и целевая метрика (F1-score) до какого момента, после чего болтается около одного значения при продолжающемся росте ошибке, т.е. явном переобучении.\n",
      "----------------------------------------\n",
      "зачем тебе дожидаться, если ты хочешь просто поучиться?\n",
      "----------------------------------------\n",
      "Какой objective лучше использовать при бинарной классификации с несбалансированными классами? вообще интересует максимизация pr auc на маленьком классе, есть какой-то лосс который может помочь быстрее это выучить?\n",
      "----------------------------------------\n",
      "А можно чуть подробнее? Какое изначальное допущение на модель, что является результатом?\n",
      "----------------------------------------\n",
      "Какова структура “соединения”, скажем так, моделей?\n",
      "----------------------------------------\n",
      "Какое предположение нам нужно принять, чтобы финальный слой был softmax?\n",
      "----------------------------------------\n",
      "Какие можно использовать архитектуры для классификации последовательностей тектов? На ум приходит что-то вроде LSTM, которая на первом урочне получает последовательность текстов, а на втором смотрит на текст на последовательность слов\n",
      "----------------------------------------\n",
      "Кто помнит, какие mean values по каналам на ImageNet?\n",
      "----------------------------------------\n",
      "Подскажите такую штуку. Когда у нас в сети convolution layer и подаётся 3 канала на вход, то это значит что одинаковые фильтры применяются ко всем трём каналам?\n",
      "----------------------------------------\n",
      "Одна из проблема на задаче про спутники, с которой я мучаюсь - это нахождение Вьетнамских тарантасов с высоты пртичьего полета на спутниковых снимках. Image Segmentation не справляется. Есть идея использовать оконный детектор. Кто мне подскажет грамотную литературу, а лучше сразу сетку, которая с этой задачей может успешно сработать?\n",
      "----------------------------------------\n",
      "кто-нибудь уже успел пощупать java api у tf?\n",
      "----------------------------------------\n",
      "Кто нибудь в курсе, как в керасе задать количество потоков?\n",
      "----------------------------------------\n",
      "Кто тут работал со слоем Cropping2D в Keras? Есть пара вопросов?\n",
      "----------------------------------------\n",
      "Как в :tensorflow: делать аналог `theano.clone`? Что-то я так и не понял есть там это или нет\n",
      "----------------------------------------\n",
      "Какой framework наименее прожорливый по памти? Хочется больших сетей с большими батчами. :mxnet:  ?\n",
      "----------------------------------------\n",
      "когда-то обсуждали ансамблирование сеток снапшотами (ну я это на хакатоне про ээгшки юзал в том числе), вон пейпер есть оказывается очень разумный почти про это, идея с тригонометрическим лернинг рейтом чтоб вылетать из минимумов очень забавная <https://openreview.net/forum?id=BJYwwY9ll&amp;noteId=BJYwwY9ll>\n",
      "----------------------------------------\n",
      "А кто-нибудь работал с автоэнкодерами sequence to sequence или VAE, которые должны генерить последовательности? Я вот сейчас в блоге кераса натолкнулся вот на такой кусок кода:\n",
      "```\n",
      "inputs = Input(shape=(timesteps, input_dim))\n",
      "encoded = LSTM(latent_dim)(inputs)\n",
      "\n",
      "decoded = RepeatVector(timesteps)(encoded)\n",
      "decoded = LSTM(input_dim, return_sequences=True)(decoded)\n",
      "\n",
      "sequence_autoencoder = Model(inputs, decoded)\n",
      "encoder = Model(inputs, encoded)```\n",
      "также видел примеры кода, когда примерно такую же архитектуру использовали для декодера в variational autoencoder.\n",
      "Мне показалось немного странным, что для декодера на каждом таймстепе используют один и тот же вход.   Это стандартная практика? Кажется, что на вход лучше бы подавать выход с предыдущего таймстепа или использовать teacher forcing (подавать на вход исходную последовательность). Кто нибудь может поделиться своим опытом?\n",
      "----------------------------------------\n",
      "хочу под ubuntu 16.04 desktop заставить работать встроенную intel карточку для рендеринга gym. Сейчас никакой display manager не запущен, хожу только по ssh. `lightdb start` или `status` выдает `update-alternatives: error: no alternatives for x86_64-linux-gnu_gfxcore_conf`, `prime-select intel` ничего не меняет. драйвера переустанавливал меньше месяца назад из nvidia ppa. Подсажите в какую сторону копать? Как сказать lightdm забить на nvidia?\n",
      "----------------------------------------\n",
      "привет. кто-то видел web-based апликуху для image labeling?  нужно подготовить training set для image classification\n",
      "типа Amazon MechanicalTurk только standalone\n",
      "----------------------------------------\n",
      "какая будет примерно закономерность на тесте?  как выбирать критерий остановки при тренировке?\n",
      "----------------------------------------\n",
      "какой метод из keras лучше использовать для уменьшения lr?\n",
      "----------------------------------------\n",
      "Вопрос обывателя. Как к такой архитектуре можно прийти? принять что-то? Сходу не сказать что есть какая-то логика.\n",
      "<https://media.licdn.com/mpr/mpr/AAEAAQAAAAAAAAoQAAAAJDMyYzgyYzRhLTg1NjUtNDg1Yy1hMjY0LTJjZWFiMzJkOTk1NQ.png>\n",
      "<https://www.linkedin.com/pulse/duplicate-quora-question-abhishek-thakur>\n",
      "----------------------------------------\n",
      "Котаны, такой вопрос. Хочу взять уже предобученную сеть (например, resnet50 на imagenet) из keras.applications и что-нибудь ей предсказать. При предсказании модели и используется CPU, а не GPU. Как-нибудь можно на GPU предсказывать?\n",
      "\n",
      "<https://keras.io/applications/>\n",
      "----------------------------------------\n",
      "Накодил небольшую библиотеку на theano, забавы ради, можно сказать. Если я запускаю код в jupyter notebook единым блоком, всё работает отлично. Если запускаю тот же код кусок за куском, кернел падает без какого-либо трейсбэка. Если запускать через командную строку файл ноутбука, переконверченный в .py, всё работает нормально, но когда-то умирало с ошибкой floating point exception: 8, тоже без трейсбэка. Как эту жуть дебажить?:sweat_smile: до этого библиотека была на tf и работала исправно, в коде никаких очевидных ошибок нет\n",
      "----------------------------------------\n",
      "Кто-нибудь пробовал это на практике использовать?\n",
      "----------------------------------------\n",
      "Какие англицизмы больше всего режут глаз? Может поправлю\n",
      "----------------------------------------\n",
      "Какие есть практики работы с пропущенными значениями в нейросетках? У меня они ща как 999999 закодированы и это наверно ппц)\n",
      "----------------------------------------\n",
      "Кто к курсе, можете прояснить ситуацию с Керас? Как там у них дела обстоят?\n",
      "То, что удалось выцепить: <https://github.com/fchollet/keras/issues/5299> обозначил, что Keras теперь - это не либа, а набор спецификаций API. Этот набор будет имплементироваться в Keras-2 (новая инкарнация либы) и отдельно в tf.contrib.keras (-&gt;tf.keras). keras-contrib, вроде как, будет содержать какие-то куски типа лосс функций, метрик, слоёв,  и т.д. которые недостаточно хороши для Keras-2 (которая, как бы, будет LTS), но и не полный мусор (потому что какие-то типы уже назвались мэинтейнерами и довольно критично всё ревьюят).\n",
      "Далее, вроде бы совместимость с TF 1.0 есть (<https://github.com/fchollet/keras/pull/5317>, <https://github.com/fchollet/keras/issues/5623> и т.д.), но модели в <https://github.com/fchollet/keras/tree/keras-2/keras/applications> используют старые ссылки на веса. Кто-н их тестил, они вообще работают теперь?\n",
      "В продолжение предыдущего вопроса, pre-trained модели теперь можно где-н найти рабочие? <https://github.com/tensorflow/models>, судя по issues&amp;PRs сильно отстают от движухи, и с TF 1.0 работают всего несколько штук. С <https://github.com/fchollet/deep-learning-models> ситуация вроде бы как с <https://github.com/fchollet/keras/tree/keras-2/keras/applications>.\n",
      "Последний вопрос: какой бранч Кераса теперь хостится в PyPi? Keras-1? Keras-2?\n",
      "----------------------------------------\n",
      "Чем он лучше предыдущих? Быстрее тренируется? Достигает лучшего результата? Как это в цифрах показать?\n",
      "----------------------------------------\n",
      "Чат, киньте в меня ссылкой или мыслями на тему плиз. Кто-нибудь пытался совместить SGD с динамическим обновлением весов примеров по типу adaboost?\n",
      "Мотивация такая: в задачах классификации, если датасет сильно несбалансированный, то классы, у которых гораздо больше примеров, задавливают общий лосс и на редких классах модель может сильно ошибаться. Это можно лечить колхозом с увеличением важности редких классов ручками (гемор, добавляет гиперпараметры). Либо делать что-то (не знаю точно как) в ключе GAN. С другой стороны, Adaboost должен автоматически отрегулировать веса примеров оптимальным образом. Тренить много сеток как weak learners при этом особо не надо, т.к. обычно capacity одной сети уже избыточна. Получается, что SGD на одной сетке с Adaboost весами должно работать лучше на классификации (игнорируя оверфит для простоты). Логично или что-то упускаю?\n",
      "----------------------------------------\n",
      "Кто нибудь в курсе почему в YOLO не пользуют ResNet?\n",
      "----------------------------------------\n",
      "Кто-нибудь знает, авторы вот этой статьи в нашем дружном чатике присутствуют? <https://arxiv.org/abs/1701.06643>\n",
      "----------------------------------------\n",
      "Кто-нибудь пробовал Batch Renormalization <https://arxiv.org/pdf/1702.03275.pdf> или проблема маленьких батчей пока ни у кого не стоит?\n",
      "----------------------------------------\n",
      "почему люди вообще этим пользуются?\n",
      "----------------------------------------\n",
      "каким местом нужно писать фреймворк, чтобы так получилось?\n",
      "----------------------------------------\n",
      "какие у меня перспективы сейчас есть в области конвертации не совсем простой модели на каффе на что-то юзабельное?\n",
      "----------------------------------------\n",
      "Кто-нибудь уже проверял Unet на Keras 2 + TF не стал ли случайно быстрее, чем Keras 1 + TH ?\n",
      "\n",
      "<@U07V1URT9> Вы спутники на TH или TF полируете?\n",
      "----------------------------------------\n",
      "кто знает, в связи с чем поменяли? выходные слои в Keras applications.inception_v3\n",
      "было\n",
      "```\n",
      "if include_top:\n",
      "        # Classification block\n",
      "        x = AveragePooling2D((8, 8), strides=(8, 8), name='avg_pool')(x)\n",
      "        x = Flatten(name='flatten')(x)\n",
      "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
      "```\n",
      "стало\n",
      "```\n",
      "if include_top:\n",
      "        # Classification block\n",
      "        x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
      "        x = Dense(classes, activation='softmax', name='predictions')(x)\n",
      "```\n",
      "<https://github.com/fchollet/deep-learning-models/blob/master/inception_v3.py>\n",
      "в пейперах не нашёл детального описания выходных слоёв, только inception blocks, но помню где то видел именно последний вариант\n",
      "имхо он имеет ряд преимуществ\n",
      "----------------------------------------\n",
      "Кто-нибудь пользовался float16 на lasagne на карточках паскаль?\n",
      "----------------------------------------\n",
      "1. Как понять, чем занята память на GPU ? Делаю finetune на vgg16 c отрубленной головой (без двух последних fc)  Через несколько итераций из gpu памяти остается порядка 100Mб (из 12Гб), причем никаких внешних shared vars кроме весов vgg16 без fc явно не создаю.  \n",
      "2. Как посмотреть, сколько памяти требуется theano для весов и промежуточных вычислений? Кажется для весов достаточно посмотреть на вывод `np.sum([p.size.eval() for p in lasagne.layers.get_all_params(&lt;last_net_layer&gt;)])`, а как посмотреть, сколько нужно для промежуточных вычислений ?\n",
      "----------------------------------------\n",
      "Как обычно называют Fold или KFold по-русски?\n",
      "----------------------------------------\n",
      "А можешь подробнее про \"каждому прокси назначается метка класса\". Как вычислить координату этой точки?\n",
      "----------------------------------------\n",
      "Кто-нибудь из оригиналов, работающих на Win10+Theano/TF как-то побеждал тот факт, что WDDM не даёт больше 80% видеопамяти использовать?\n",
      "----------------------------------------\n",
      "Кто-нибудь знает об общественно полезных случаях применения GAN?\n",
      "----------------------------------------\n",
      "какой must заботать по deeplearning кроме <http://cs231n.github.io>?\n",
      "----------------------------------------\n",
      "<@U3HM4KY14> убрал девайс. Запустилось. По данным nvidia-smi аллоцирована память ток на одной тачке, CPU-Util в пике 20%. Почему не 100% или около того? Значит ли эта, что карточка не используется? Как проверить, что карточка нагружается? По скорости по сравнению с cpu улучшения заметного нет.\n",
      "----------------------------------------\n",
      "Есть вопрос по Keras. В последних версияз появились соответственно Pretrained сетки, которые можно вызвать.\n",
      "from keras.applications.vgg16 import VGG16\n",
      "vgg16 = VGG16(include_top=False, weights='imagenet')\n",
      "\n",
      "Вопрос в следующем. Как потом сюда прикрутить в конец, например, Dense? Я это сделал, но через танцы с бубном, вытащив саму функцию и переделав под свои нужды. Мне кажется должен быть элегантный вариант в одну строку.\n",
      "----------------------------------------\n",
      "Я вот все равно ни черта не понял. Что за физический процесс? Зачем его предсказывать если он детерменирован? Что за сеть?\n",
      "----------------------------------------\n",
      "Как сказал Андрей Киселев: И че? \n",
      "----------------------------------------\n",
      "Друзья, а как выбирать window_size и количество скрытых нейронов в lstm? Как они к друг другу должны соотносится? Если какие-то эвристики? Мне наивно кажется что 1 к 1 норм, но я даже и это нагуглить не смог :dolan: \n",
      "----------------------------------------\n",
      "Кто-нибудь сталкивался с задачей понимания что делает каждый фильтр в CNN ? Конкретнее, у меня CNN для time-series  c 1D свертками, мб есть какой-то более четкий способ чем то как делают в статьях про CNN и котиков (я нашел что выбирают или даже как-то частично генерят котиков которые сильнее всего активируют конкретный фильтр и рисуют feature map)\n",
      "----------------------------------------\n",
      "Как я уже писал в другом среаде, кому будет полезен мой код и мой труд, если мой скор будет на уровне 30% или даже 20%? Как пример, если бы велась сейчас МЛ разработка на Mycroft AI - это совсем другое дело. Добавил какой-то функционал, стянул апгрейд и твой личный voice assistant получил новые возможности.\n",
      "----------------------------------------\n",
      "Нубский вопрос, можно ли взять что-нибудь сложное из model zoo, типа U-net, и тренировать его как BNN, или там нужны другие архитектуры? Какие преимущества у BNN перед традиционными DNN?\n",
      "----------------------------------------\n",
      "Кто там хотел примеров сетей без картинок, звука и текстов? <https://twitter.com/KyleCranmer/status/848959715472277505>\n",
      "----------------------------------------\n",
      "Всем привет. У меня очередной затык с rnn-ками в tensorflow. Надеюсь на вашу помощь.\n",
      "\n",
      "Вопрос: как работает у dynamic_rnn параметр sequence_length? Как брать последний выход и последний скрытый слой? (он копируется в конец массива или нет?)\n",
      "\n",
      "Конкретная проблема: есть простая сеть\n",
      "```x_input = tf.placeholder(tf.float32, [None, max_steps, num_features])\n",
      "x_input_len = tf.placeholder(tf.int64, [None])\n",
      "y_input = tf.placeholder(tf.int64, [None])\n",
      "cell = tf.contrib.rnn.LSTMCell(128)\n",
      "outputs, states = tf.nn.dynamic_rnn(cell=cell, inputs=x_input, sequence_length=x_input_len, dtype=tf.float32) \n",
      "output = outputs[:, -1, :]\n",
      "logits = tflearn.fully_connected(output, 10)\n",
      "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y_input)\n",
      "loss = tf.reduce_mean(cross_entropy)\n",
      "optimize = tf.train.AdamOptimizer(learning_rate).minimize(loss)```\n",
      "\n",
      "Она не сходится (на 10-классовой классификации выдает accuracy стабильно 8.75% и дальше не идет).\n",
      "Проблема решается, если:\n",
      "- заменить output = outputs[:, -1, :] на output = states.c\n",
      "- убрать параметр sequence_length\n",
      "Не понимаю, как это работает и почему это так. Прошу объяснить.\n",
      "\n",
      "Я полагал, что последний output (т.е. outputs[:, -1, :]) - это то же самое, что states.c, но, почему-то это не так\n",
      "----------------------------------------\n",
      "Кто-то натыкался на готовые веса предобученные на imagenet или mscoco для Keras под ResNet-152?\n",
      "----------------------------------------\n",
      "Как подготавливают данные при задачах локализации?\n",
      "\n",
      "Для классификации можно просто кропать, для сегментации тоже.\n",
      "\n",
      "А вот если у нас есть картинка 400x1000 и на ней что-то выделено в bounding box.\n",
      "\n",
      "Что обычно делают? Перегоняют под квадрат, забивая на то, что изображение сплющит по горизонтали?\n",
      "\n",
      "Кропают?\n",
      "----------------------------------------\n",
      "Необходимо на изображении выделять обпределенные объекты в bounding box. Сами объекты могут быть сильно разные по размеру. Какой метод на данный момент лучше выбрать? Желательно чтобы сеть это выполняла в один проход. Пока остановился на сети yolo <https://pjreddie.com/media/files/papers/yolo_1.pdf>\n",
      "----------------------------------------\n",
      "господа tensorflow-фаги посоветуйте, пожалуйста, набор батареек для сетестроительства над tf. Что-то в стиле Lasagne для theano.\n",
      "Кто-нибудь полузет tf.slim, tf learn, sonnet?\n",
      "----------------------------------------\n",
      "Господа, помогите разобраться начинающему, пожалуйста.\n",
      "\n",
      "Разбираю пример классификации изображений: <https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/udacity/4_convolutions.ipynb>\n",
      "\n",
      "Цель — на своих данных распознавать не 10 классов (как в примере), а 250.\n",
      "(Картинки как в примере — 28х28,просто чёрно-белые, визуально распознаются норм)\n",
      "Похоже что не достаточно изменить только размер выходного слоя (сеть просто не сходится), а нужно изменить ещё гиперпараметры (?)\n",
      "\n",
      "Наверное надо поставить batch_size такого размера чтобы в каждом шаге были примеры каждого класса.\n",
      "Опытным путём на 200ах классах пришёл к\n",
      "batch_size = 500\n",
      "patch_size = 15\n",
      "Буквально небольшое изменение — сеть опять не сходится.\n",
      "\n",
      "Ну ок, обучаюсь. Сохраняю граф вычислений для использования в другом месте, а он весит 100 мегабайт, как-то многовато.\n",
      "\n",
      "Вопрос 1. Верны ли мои рассуждения относительно параметров и сходимости сети? Или причина несходимости сети при увеличении классов на порядок может быть в другом?\n",
      "Вопрос 2. Почему граф такой простой сети столько весит? Что я делаю не так? Как уменьшить?\n",
      "----------------------------------------\n",
      "Есть интересный вопрос. Я сейчас смотрю на загрузку GPU, особенно это видно на Inference - она близка к 0, потомучто почти всё время уходит на генерацию батчей. Как бы это сделать в параллели? Кто-то писал код на Keras который это решает? Мб ссылочки есть?\n",
      "----------------------------------------\n",
      "Кто-нибудь понимает о чём этот мужик пишет? <https://habrahabr.ru/post/326334/>\n",
      "----------------------------------------\n",
      "Кто может напомнить, почему в VGG / Resnet на вход идут BGR, а не RGB?\n",
      "----------------------------------------\n",
      "Кто-нибудь проверял, mxnet заводится с cudnn 6?\n",
      "----------------------------------------\n",
      "Кто-нибудь смотрел, на каких-нибудь других лоссах помимо NCA?\n",
      "----------------------------------------\n",
      "Кто-нибудь подскажет ссылки на работы, когда авторы добавляли batch normalization к VGG и как это что-то меняло?\n",
      "----------------------------------------\n",
      "как обычно проверяют сходимость параметров?\n",
      "----------------------------------------\n",
      "Ооо, спасибо большое!!! Наконец-то всё прояснилось. Как думаете, если попробовать другую реализацию Faster-RCNN не из mxnet, тоже с этим можно столкнуться?\n",
      "----------------------------------------\n",
      "Кто-нибудь пробовал dilated LSTM ?\n",
      "<https://arxiv.org/pdf/1703.01161.pdf#page.5>\n",
      "----------------------------------------\n",
      "кто нибудь пробовал MR-RNN ?\n",
      "----------------------------------------\n",
      "как я понимаю, это все очень затратно и по памяти и по времени, правильно?\n",
      "----------------------------------------\n",
      "как думаете, какой объем картинок будет достаточен, чтобы добиться более-менее точности?\n",
      "----------------------------------------\n",
      "Оффтоп от темы параллельных вычислений. Немного нубовские вопросы интересуют. Подскажите, как выбрать метод оптимизации для задачи классификации изображений, используя модели типа resnet50, inception v3? Различные методы находят минимумы с разной скоростью (Adadelta, Adam). Какие методы вы используете и почему? И как правильно подобрать learning rate, на скольки эпохах?\n",
      "----------------------------------------\n",
      "Френз, в статье про U-Net авторы всё пишут, что ей нужно \"very few training images\". Кто реально использовал, very few - это какого порядка размер датасета?\n",
      "----------------------------------------\n",
      "Кто понял из сайта, будут записи?\n",
      "----------------------------------------\n",
      "кто писал кастомный генератор для Keras есть вопрос, падает после нескольких эпох и причина не понятна?\n",
      "----------------------------------------\n",
      "Кто-нибудь использовал Keras через tensorflow.contrib?\n",
      "\n",
      "<https://github.com/tensorflow/tensorflow/tree/master/tensorflow/contrib/keras>\n",
      "----------------------------------------\n",
      "Кому-нибудь попадался туториал для чайников как перебить в mxnet SSD или Faster RCNN чтобы это тренировалось на другом датасете? Там какие-то нюансы с созданием rec файлов и что-то где-то у меня идет не так.\n",
      "----------------------------------------\n",
      "Кто-то встречал работы в которых объясняется как одноцветный фон изображений  влияет на процес обучения в сверточных сетях? Например, у нас есть датасет где много изображений не квадратны, соответственно чтобы их поместить в квадрат мы вертикальное или горизонтальное оствшееся место заполняем каким-то цветом. Иногда фон может занимать больше 50%. Я вот заметил, что черный цвет это плохо, белый - хорошо (у меня были почти все изображения где фона больше, и при черном я получил оверфит тупо в один класс, в то время как с белым фоном все было ок). Моя нубская догадка в том что при белом цвете (из-за максимального значения), мы находимся в максимуме из которого проще скатиться в минимум и наоборот для черного. Что вы думаете?\n",
      "----------------------------------------\n",
      "кто что знает про Running Minimum stopping criteria?\n",
      "----------------------------------------\n",
      "какой лосс может быть лучше, если не закапываться в метрик лернинг?\n",
      "----------------------------------------\n",
      "Кто-нибудь пользовался новым seq2seq у tensorflow (1.1)? Никак не могу туда воткнуть attention, то ему одно не нравится, то другое.\n",
      "----------------------------------------\n",
      "Как у Keras c tf backend сказать tf, что вот это GPU можно использовать, а вот это трогать не надо?\n",
      "\n",
      "А то сейчас tf резервирует под себя оба GPU, а считает только на одном.\n",
      "\n",
      "В th это решалось ` THEANO_FLAGS=mode=FAST_RUN,device=gpu1,floatX=float32 python resnet.py`\n",
      "----------------------------------------\n",
      "привет, один товарищ спрашивает, можно ли решить задачу распознавания цвета волос (по шкале от 1 до 10) по снимку обычной камерой в обычных условиях. датасет готов собирать, какой нужен будет (например, снимок волос и рядом образец известного цвета). я так понимаю, тут проблема в текстуре и балансе белого может быть. кто-то что-то подобное делал или слыхал?\n",
      "----------------------------------------\n",
      "Привет! Помогите, пожалуйста. Как установить tflearn для анаконды?\n",
      "----------------------------------------\n",
      "Как перевести на английский комитет нейронных сетей?\n",
      "----------------------------------------\n",
      "Как правильнее настраивать гиперпараметры нейронок и какие из них важнее?\n",
      "----------------------------------------\n",
      "Кто-то пользовался этим, чтобы веса сеток хранить?\n",
      "<https://git-lfs.github.com/>\n",
      "----------------------------------------\n",
      "Кто-нибудь реализовывал end-to-end ASR/Text2Speech системы? Мучаюсь с Listen, Attend and Spell, никак не сходится. Но в работе есть темные места (и опыта с NN у меня мало). Буду рад, если кто-то сможет помочь (готов и консультацию взять).\n",
      "----------------------------------------\n",
      "Кто шарит как красиво объединять сетки? Обучил несколько сеток, собрал фичи с последнего слоя в csv и у той и у другой. Потом пробовал и новую сетку обучить на этих фичах и xgb, но результат получается даже хуже чем у любой отдельно взятой. Даже просто усредненные вероятности дают лучше результат. если вместе учить, объединив через ConcatLayer полная беда со сходимостью (кажется,  что одна сеть просто быстрее учится и забивает другую). \n",
      "\n",
      "----------------------------------------\n",
      "как собрать торча без конды?\n",
      "----------------------------------------\n",
      "Привет! Такой вопрос: пытаюсь улучшить разрешение карты загрязнения воздуха (из 34х34 в 102х102) с помощью сетки для сегментации (тирамису с двумя входами для картинок размерностью 2 и 6 (а не как 3 у ргб)). По пути у меня несколько решейпов на данные ( для таргета из (102, 102, -1) в (-1, 102, 102, 1), например), потом получаются такие картинки (слева таргет, справа предсказанное). Почему такие разбросы в значениях, откуда артефакты (и как от них избавиться)? Спасибо\n",
      "----------------------------------------\n",
      "какую максимальную длину ты брал?\n",
      "----------------------------------------\n",
      "Какова характерная длина искомых особенностей и сколько каналов в векторах?\n",
      "----------------------------------------\n",
      "Ты задачу то и не описала толком. Если последовательностей много, но разной длины, тогда сама длина может быть дурацкой суперфичей.\n",
      "Какая природа у последовательности btw?\n",
      "ДНК какая-нибудь? Тогда можно почанкать и word2vec посчитать.\n",
      "----------------------------------------\n",
      "Как думаете, с помощью чего можно добиться похожих результатов как в этой статье? <https://geektimes.ru/post/288548/?mobile=no>\n",
      "----------------------------------------\n",
      "есть numpy.array() содержащий маску изображения. каков каноничный способ отресайзить этот массив под новый shape изображения, чтобы маска не съехала?\n",
      "----------------------------------------\n",
      "Где-нибудь пролетал бенчмарк о том, что по скорости при параллелизации на несколько GPU мизинцем левой ноги на различных фрэймворках? Как я понимаю, паралеллизацию мизинцем на данный момент поддерживают только mxnet и pytorch?\n",
      "----------------------------------------\n",
      "Сделал такое\n",
      "```x = 2\n",
      "y = 3\n",
      "a = tf.add(x,y)\n",
      "b = tf.multiply(x,y)\n",
      "c = tf.pow(b,a)\n",
      "with tf.Session() as sess:\n",
      "    writer = tf.summary.FileWriter('logs', sess.graph)\n",
      "    print(sess.run(c))\n",
      "    writer.close()```\n",
      "поясните за стремный граф. почему там какие-то непонятные массивы, а не по одному add, mul и pow?\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for _text in map(itemgetter('text'), questions):\n",
    "    print(_text)\n",
    "    print('-'*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
